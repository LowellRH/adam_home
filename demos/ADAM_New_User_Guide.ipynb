{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome new ADAM user!\n",
    "\n",
    "   This notebook will guide you through a few ADAM features and validate that your system is configured correctly.  \n",
    "\n",
    "   Before starting this notebook, you should have already run the config_demo.ipynb notebook on your system (located in adam_home/demos).  Additionally, please ensure that you have installed Astroquery on your system (instructions in FAQ).    \n",
    "   \n",
    "   \n",
    "Currently, as of 25-MAR-19, this notebook supports the following features. \n",
    "\n",
    "-Pulls trajectory data for a given object and timeframe from NASA JPL\n",
    "\n",
    "-Propagates trajectory for that same object in ADAM. \n",
    "\n",
    "-Plots orbits for ADAM and JPL data.  \n",
    "\n",
    "-Exports ADAM Data in CSV format\n",
    "\n",
    "-Exports JPL Data in CSV format\n",
    "\n",
    "-Calculates and displays RIC for ADAM vs JPL\n",
    "\n",
    "- Exports ADAM ephemeris as .e file. \n",
    "\n",
    "\n",
    "In Development\n",
    "\n",
    "- Transform ADAM data to rotate from EMEME2000 to ICRF\n",
    "\n",
    "- Add option to output JPL data as .e \n",
    "\n",
    "\n",
    "NOTES: \n",
    "\n",
    "-This version currently defaults to the dev server since, as of 07-MAR-19, the production side is pending updates.\n",
    "\n",
    "-This version is written to read the astro folder from within \"adam_home\".  You may need to point the code in the next cell to your Astro folder.    \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This imports libraries from ADAM and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This specifies the path to the adam_home folder and configuration file on your system.\n",
    "import sys\n",
    "from os.path import expanduser\n",
    "adam_home_defined = expanduser(\"~\") + \"/adam_home\" # default location\n",
    "config_folder=expanduser(\"~\") + \"/adam_home/config\" # default location  # Works,  19 Feb -LRH\n",
    "import adam\n",
    "\n",
    "# This imports the necessary libraries from ADAM and JPL as well as other packages. \n",
    "from adam import Batch\n",
    "from adam import Batches\n",
    "from adam import BatchRunManager\n",
    "from adam import PropagationParams\n",
    "from adam import OpmParams\n",
    "from adam import ConfigManager\n",
    "from adam import Projects\n",
    "from adam import RestRequests\n",
    "from adam import AuthenticatingRestProxy\n",
    "import time\n",
    "import os\n",
    "from adam import Service\n",
    "from adam import Batch\n",
    "from adam import PropagationParams\n",
    "from adam import OpmParams\n",
    "from adam import BatchRunManager\n",
    "from adam import ConfigManager\n",
    "import unittest\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.testing as npt\n",
    "from adam.batch import StateSummary\n",
    "from adam.batch import PropagationResults\n",
    "\n",
    "#Astro Query\n",
    "from astroquery.jplhorizons import Horizons\n",
    "from astroquery.jplhorizons import conf\n",
    "conf.horizons_server = 'https://ssd.jpl.nasa.gov/horizons_batch.cgi'\n",
    "\n",
    "\n",
    "\n",
    "#NOTE: This version is written to read the astro folder from within \"adam_home\". You may need to move astro to this folder. \n",
    "#If the astro folder is not in adam_home, please modify the next line to point to your \"astro\" folder. \n",
    "#sys.path.insert(0,'C:\\\\Users\\\\Lowell\\\\adam_home\\\\astro') \n",
    "#astro Lib\n",
    "from astro import Transform\n",
    "from astro import asteroid_database\n",
    "  \n",
    "\n",
    "\n",
    "#Other Lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "\n",
    "# Define Constants\n",
    "GM = 132712440041.93938   #From JPL Horizons\n",
    "AU_Meters = 1.49597870e+11  # Astronomical Units in meters  \n",
    "AU_Km = 149597870.0     # conversion from AU to km \n",
    "AU_per_day = 1731456.84 # AU/Day converted to Meters per second\n",
    "# From NASA JPL.  The astronomical unit (au) is defined by the IAU as exactly 149,597,870,700 m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Asteroid and pull from JPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter asteroid target number. e.g for Eros use 433. IDs can be searched here: https://ssd.jpl.nasa.gov/sbdb.cgi#top \")\n",
    "asteroid = input() #in form of target number i.e. for Eros use 433\n",
    "\n",
    "# You can edit the inputs below to change the start/stop times and the step size.  \n",
    "start_time_str='2016-10-04T00:00:00' #YYYY-Mon-Dy {HH:MM}   #Default: start_time_str='2016-10-04T00:00:00'\n",
    "end_time_str='2017-10-11T00:00:00'   # Default: end_time_str='2017-10-11T00:00:00'\n",
    "step = '1d'   #Default:  1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Repeated 2 cells down???\n",
    "\n",
    "#call the object\n",
    "\n",
    "obj = Horizons(id=str(asteroid), location=None ,epochs={'start':start_time_str, 'stop':end_time_str,'step':step})\n",
    "vec = obj.vectors() #state vector at each epoch, inital state vector is initial epoch\n",
    "#vec is the entire epheremris over the specified timeframe, the inital state vector (to be put into ADAM) is vec's first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simplified Dataframe\n",
    "\n",
    "eph_JPL_df = pd.DataFrame(\n",
    "    {'Time [Barycentric TBD]': vec['datetime_jd'],\n",
    "     'x [m]': vec['x']*AU_Meters,#1.496e+11,\n",
    "     'y [m]': vec['y']*AU_Meters,#1.496e+11,\n",
    "     'z [m]': vec['z']*AU_Meters,#1.496e+11,\n",
    "     'x_dot [m/s]': vec['vx']*AU_per_day,#1731456.84,\n",
    "     'y_dot [m/s]': vec['vy']*AU_per_day ,#1731456.84,\n",
    "     'z_dot [m/s]': vec['vz']*AU_per_day, #1731456.84\n",
    "     \n",
    "    })\n",
    "# eph_JPL_df    # Commented out to improve readibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the object\n",
    "obj = Horizons(id=str(asteroid), location=None ,epochs={'start':start_time_str, 'stop':end_time_str,'step':step})\n",
    "vec = obj.vectors() #state vector at each epoch, inital state vector is initial epoch\n",
    "\n",
    "#JPL Cartesian State Vector + Data Frame\n",
    "JPL_SV = np.array([vec[i][0] for i in vec.columns])\n",
    "JPL_SV_df_cart = pd.DataFrame(JPL_SV, index= vec.columns, columns=list(' ')) \n",
    "#JPL r and v vectors\n",
    "JPL_r = np.array([np.float(i) for i in JPL_SV[5:8]])*AU_Km#1.496e+8\n",
    "JPL_v = np.array([np.float(i) for i in JPL_SV[8:11]])*(AU_per_day/1000) # KM per second  1731.46\n",
    "print(\"Position: %s km\" % JPL_r)\n",
    "print(\"Velocity: %s km/s\" % JPL_v)\n",
    "#########################################################################\n",
    "#Converting to Keplerian \n",
    "d2r = np.pi/180.\n",
    "r2d = 180./np.pi\n",
    "trans = Transform()\n",
    "\n",
    "JPL_a, JPL_e, JPL_i, JPL_node, JPL_w, JPL_TA = trans.cartesian_to_classical(JPL_r,JPL_v)\n",
    "kep_col = np.array(['SMA','Ecc','Inc','RAAN','Arg of per','True anomaly'])\n",
    "\n",
    "JPL_SV_df_kep = pd.DataFrame(np.array([JPL_a, JPL_e, JPL_i*r2d, JPL_node*r2d, JPL_w*r2d, JPL_TA*r2d]), index= kep_col, columns=list(' ')) \n",
    "#Combining two dataframes\n",
    "JPL_SV_df = pd.concat([JPL_SV_df_cart, JPL_SV_df_kep], axis=0) \n",
    "# JPL_SV_df  # Again, commented out to avoid excessive outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Minor Planet Center Queries\n",
    "\n",
    "from astroquery.mpc import MPC\n",
    "mpc = MPC()\n",
    "result = mpc.query_object_async(number=asteroid, target_type=\"asteroid\")\n",
    "#result.json()   # Remove # to see results\n",
    "#[{'absolute_magnitude': '3.34', 'aphelion_distance': '2.976', 'arc_length': 79247, 'argument_of_perihelion': '73.11528', 'ascending_node': '80.3099167', 'critical_list_numbered_object': False, 'delta_v': 10.5, 'designation': None, 'earth_moid': 1.59353, 'eccentricity': '0.0755347', 'epoch': '2018-03-23.0', 'epoch_jd': '2458200.5', 'first_observation_date_used': '1801-01-31.0', 'first_opposition_used': '1801', 'inclination': '10.59351', 'jupiter_moid': 2.09509, 'km_neo': False, 'last_observation_date_used': '2018-01-20.0', 'last_opposition_used': '2018', 'mars_moid': 0.939285, 'mean_anomaly': '352.23052', 'mean_daily_motion': '0.2141308', 'mercury_moid': 2.18454, 'name': 'Ceres', 'neo': False, 'number': 1, 'observations': 6689, 'oppositions': 114, 'orbit_type': 0, 'orbit_uncertainty': '0', 'p_vector_x': '-0.87827466', 'p_vector_y': '0.33795664', 'p_vector_z': '0.33825868', 'perihelion_date': '2018-04-28.28378', 'perihelion_date_jd': '2458236.78378', 'perihelion_distance': '2.5580384', 'period': '4.6', 'pha': False, 'phase_slope': '0.12', 'q_vector_x': '-0.44248615', 'q_vector_y': '-0.84255514', 'q_vector_z': '-0.30709419', 'residual_rms': '0.6', 'saturn_moid': 6.38856, 'semimajor_axis': '2.7670463', 'tisserand_jupiter': 3.3, 'updated_at': '2018-02-26T17:29:46Z', 'uranus_moid': 15.6642, 'venus_moid': 1.84632}]\n",
    "#MPC Eph database\n",
    "#https://minorplanetcenter.net/iau/MPEph/MPEph.html?format=json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result.content   # Probably don't need to keep this one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagate through ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads your config from a file in current directory. For instructions on setting this up, see config_demo notebook.\n",
    "config = ConfigManager(config_folder + '/adam_config.json').get_config(\"dev\")  # remove \"dev\" to default to prod\n",
    "service = Service(config)\n",
    "service.setup()\n",
    "auth_rest = AuthenticatingRestProxy(RestRequests(config.get_url()), config.get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_project = service.new_working_project() # cleans up old batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Keplerian Parameters\n",
    "start_time_str_Z=start_time_str+'Z'\n",
    "end_time_str_Z=end_time_str+'Z'\n",
    "\n",
    "#keplerian Method:\n",
    "keplerian_elements = {\n",
    "    'semi_major_axis_km': np.float(JPL_SV_df.iat[14,0]),\n",
    "    'eccentricity': np.float(JPL_SV_df.iat[15,0]),\n",
    "    'inclination_deg': np.float(JPL_SV_df.iat[16,0]),\n",
    "    'ra_of_asc_node_deg': np.float(JPL_SV_df.iat[17,0]),\n",
    "    'arg_of_pericenter_deg': np.float(JPL_SV_df.iat[18,0]),\n",
    "    'true_anomaly_deg': np.float(JPL_SV_df.iat[19,0]),\n",
    "    'gm': 132712440041.93938 # FROM JPL Horizons                                    \n",
    "}\n",
    "propagation_params = PropagationParams({\n",
    "    'start_time': start_time_str_Z,\n",
    "    'end_time': end_time_str_Z,\n",
    "    'project_uuid': config.get_workspace(),\n",
    "    'description': 'Created by test at ' + start_time_str\n",
    "})\n",
    "opm_params_templ = {\n",
    "    'epoch': start_time_str_Z,\n",
    "    'object_name': (JPL_SV_df.iat[0,0]),    # object ID\n",
    "    'object_id':asteroid\n",
    "    #'comment':\"Keplerian Coord System\"                    \n",
    "    # state_vector or keplerian_elements will be set later.\n",
    "    #'mass': 500.5,\n",
    "    #'solar_rad_area': 25.2,\n",
    "    #'solar_rad_coeff': 1.2,\n",
    "    #'drag_area': 33.3,\n",
    "    #'drag_coeff': 2.5\n",
    "}\n",
    "###################################################################################\n",
    "\n",
    "### Eventually we want to define and call these functions from elsewhere. \n",
    "#Create keplerian batch files to be put into ADAM\n",
    "def make_keplerian_batches(start_time_str, end_time_st):\n",
    "    keplerian_opm_params = opm_params_templ.copy()\n",
    "    keplerian_opm_params['keplerian_elements'] = keplerian_elements\n",
    "\n",
    "    keplerian = Batch(propagation_params, OpmParams(keplerian_opm_params))\n",
    "    return  keplerian\n",
    "\n",
    "\n",
    "kep_batch= make_keplerian_batches(start_time_str, end_time_str)\n",
    "print(kep_batch.get_opm_params().generate_opm())\n",
    "\n",
    "# Submit and wait until batch run is ready\n",
    "batches_module = Batches(auth_rest)\n",
    "BatchRunManager(batches_module, [kep_batch]).run()\n",
    "\n",
    "###################################################################################\n",
    "# Retrieve the vector at the end of the state\n",
    "def kep_single_run(self, start_time_str, end_time_str):\n",
    "    \n",
    "    #start_time_str = start.isoformat() + 'Z'\n",
    "    #end_time_str = end.isoformat() + 'Z'\n",
    "\n",
    "    keplerian = make_keplerian_batches(start_time_str, end_time_str) #batch objets\n",
    "    print(keplerian.get_state_summary().get_parts_count())\n",
    "\n",
    "    BatchRunManager(self.service.get_batches_module(), [kep_batch]).run()\n",
    "\n",
    "    keplerian_end_state = kep_batch.get_results().get_end_state_vector()\n",
    "    return keplerian_end_state\n",
    "\n",
    "# Get the end state vector \n",
    "end_state_vector = kep_batch.get_results().get_end_state_vector()\n",
    "print(\"State vector at the end of propagation:\")\n",
    "print(end_state_vector)\n",
    "###################################################################################\n",
    "#Get status and parts count\n",
    "parts_count = kep_batch.get_state_summary().get_parts_count()\n",
    "print(\"Final state: %s, part count %s\\n\" % (kep_batch.get_calc_state(), parts_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get ephemeris of specified part\n",
    "part_to_get = 0\n",
    "eph = kep_batch.get_results().get_parts()[part_to_get].get_ephemeris()\n",
    "\n",
    "_ ,eph_temp = eph.split(\"EphemerisTimePosVel\\n\\n\", 1)\n",
    "eph_temp, _ = eph_temp.split(\"\\n\\nEND Ephemeris\", 1)\n",
    "eph_temp\n",
    "\n",
    "eph_temp_split=eph_temp.split(' ')\n",
    "#eph_temp_split\n",
    "\n",
    "eph_split_fix=[]\n",
    "atomic_times=[]\n",
    "atomic_times.append(np.float(eph_temp_split[0]))\n",
    "for i in range(1, len(eph_temp_split[0::6])-1):\n",
    "    #calculate atomic time\n",
    "    temp = eph_temp_split[0::6]\n",
    "    temp_2=temp[i]\n",
    "    #print(temp_2)\n",
    "    eph_split_again,atomic_time= temp_2.split('\\n')\n",
    "    atomic_times.append(np.float(atomic_time))\n",
    "    eph_split_fix.append(np.float(eph_split_again))\n",
    "eph_split_fix.append(np.float(eph_temp_split[-1]))\n",
    "\n",
    "#print(\"Atomic Times: \", atomic_times)  #Commented out to improve readability.\n",
    "eph_split_fix.insert(0,0)\n",
    "#eph_split_fix.append(0)\n",
    "\n",
    "# Can we omit this?\n",
    "eph_temp_split[0::6]=eph_split_fix\n",
    "\n",
    "for i in range(0,len(eph_temp_split)):\n",
    "    eph_temp_split[i]=np.float(eph_temp_split[i])\n",
    "\n",
    "eph_Adam=eph_temp_split[1:len(eph_temp_split)]\n",
    "\n",
    "#changeeph_Adam from long list to list of 6 elements of statevector\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "eph_Adam_vectors=[]\n",
    "for group in chunker(eph_Adam, 6):\n",
    "    eph_Adam_vectors.append((group))\n",
    "    \n",
    "eph_Adam_x=[]\n",
    "eph_Adam_y=[]\n",
    "eph_Adam_z=[]\n",
    "eph_Adam_xdot=[]\n",
    "eph_Adam_ydot=[]\n",
    "eph_Adam_zdot=[]\n",
    "for i in range(0,len(eph_Adam_vectors)):\n",
    "    temp=eph_Adam_vectors[i]\n",
    "    eph_Adam_x.append(temp[0])\n",
    "    eph_Adam_y.append(temp[1])\n",
    "    eph_Adam_z.append(temp[2])\n",
    "    eph_Adam_xdot.append(temp[3])\n",
    "    eph_Adam_ydot.append(temp[4])\n",
    "    eph_Adam_zdot.append(temp[5])\n",
    "#############################################################################\n",
    "\n",
    "#Construct ADAM dataframe for the JPL state vector\n",
    "# 21-MAR-19,   labeled the columns\n",
    "eph_Adam_vectors = pd.DataFrame(\n",
    "    {'Time [Atomic UTC]': atomic_times,\n",
    "     'x [m]': eph_Adam_x,\n",
    "     'y [m]': eph_Adam_y,\n",
    "     'z [m]': eph_Adam_z,\n",
    "     'x_dot [m/s]': eph_Adam_xdot,\n",
    "     'y_dot [m/s]': eph_Adam_ydot,\n",
    "     'z_dot [m/s]': eph_Adam_zdot\n",
    "     \n",
    "    })\n",
    "\n",
    " # This line below constructs a seperate dataframe for RIC calculations.  \n",
    " # It's somewhate redundant, but helps keep track of which data we're using.  \n",
    "eph_JPLtoAdam_df = pd.DataFrame(\n",
    "    {'Time [Atomic UTC]': atomic_times,\n",
    "     'x [m]': eph_Adam_x,\n",
    "     'y [m]': eph_Adam_y,\n",
    "     'z [m]': eph_Adam_z,\n",
    "     'x_dot [m/s]': eph_Adam_xdot,\n",
    "     'y_dot [m/s]': eph_Adam_ydot,\n",
    "     'z_dot [m/s]': eph_Adam_zdot\n",
    "     \n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Orbits for JPL and ADAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize ADAM and JPL orbits for the object.\n",
    "\n",
    "# Let's just do Earth and object for now, this could be expanded to show other planets. \n",
    "earth = Horizons(id='Geocenter', location=None, epochs={'start':start_time_str, 'stop':end_time_str, 'step':'1d'}, id_type = 'majorbody')\n",
    "vEarth = earth.vectors()\n",
    "#sun = Horizons(id='Sun', location=None, epochs={'start':start_time_str, 'stop':end_time_str, 'step':'1d'}, id_type = 'majorbody')\n",
    "#vSun = sun.vectors()\n",
    "\n",
    "#  Get the points for JPL object   \n",
    "n = len(eph_JPL_df)\n",
    "xObj = [1]*n               # initialize X position array\n",
    "yObj = [1]*n               # initialize Y position array\n",
    "zObj = [1]*n               # initialize Z position array\n",
    "\n",
    "\n",
    "for i in range(0,n):             \n",
    "            xObj[i] = eph_JPL_df['x [m]'][i]\n",
    "            yObj[i] = eph_JPL_df['y [m]'][i]\n",
    "            zObj[i] = eph_JPL_df['z [m]'][i]           \n",
    "            \n",
    "#  Get the points for ADAM object            \n",
    "n = len(eph_Adam_vectors)           \n",
    "xADAM_Obj = [1]*n               # initialize X position array\n",
    "yADAM_Obj = [1]*n               # initialize Y position array\n",
    "zADAM_Obj = [1]*n               # initialize Z position array\n",
    "for i in range(0,n):             \n",
    "            xADAM_Obj[i] = eph_Adam_vectors['x [m]'][i]\n",
    "            yADAM_Obj[i] = eph_Adam_vectors['y [m]'][i]\n",
    "            yADAM_Obj[i] = eph_Adam_vectors['z [m]'][i]\n",
    "            \n",
    "# Earth points  \n",
    "n = len(vEarth)\n",
    "xEarth = [1]*n               # initialize X position array\n",
    "yEarth = [1]*n               # initialize Y position array\n",
    "zEarth = [1]*n               # initialize Z position array\n",
    "for i in range(0,n):             \n",
    "            xEarth[i] = (vEarth['x'][i]*AU_Meters)\n",
    "            yEarth[i] = (vEarth['y'][i]*AU_Meters)\n",
    "            zEarth[i] = (vEarth['z'][i]*AU_Meters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (In Development) Transform ADAM Vectors from ICRF to EMEME2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(eph_Adam_vectors) #len(ADAM_ICRF)    \n",
    "\n",
    "\n",
    "#Initialized transformed values\n",
    "TxvUdo = []             # initialize X position array\n",
    "TyvUdo = []              # initialize Y position array\n",
    "TzvUdo = []              # initialize Z position array\n",
    "\n",
    "for i in range (n):\n",
    "    # Transforms ADAM positions from EMEME2000 to ICRF\n",
    "    eph_ADAM_ICRF_temp = Transform.EMEME2000_to_ICRF(eph_Adam_vectors['x [m]'][i],eph_Adam_vectors['y [m]'][i],eph_Adam_vectors['z [m]'][i])       \n",
    "      \n",
    "    # Pulls, X, Y, and Z values   \n",
    "    TxvUdo.append(eph_ADAM_ICRF_temp[0])\n",
    "    TyvUdo.append(eph_ADAM_ICRF_temp[1])\n",
    "    TzvUdo.append(eph_ADAM_ICRF_temp[2])\n",
    "    \n",
    "    \n",
    "    #eph_Adam_vectors['x [m/s]'][i] = eph_ADAM_ICRF_temp[0]\n",
    "    #eph_Adam_vectors['y [m/s]'][i] = eph_ADAM_ICRF_temp[1]\n",
    "    #eph_Adam_vectors['z [m/s]'][i] = eph_ADAM_ICRF_temp[2]\n",
    "    # For now, we are transforming the coordinates and recording a new variable so that we can compare/troubleshoot.  \n",
    "    #In the future it would be simpler to replace the values as they're transformed, as in the velocity example below.  \n",
    "\n",
    "\n",
    "# Transform velocities also\n",
    "    eph_ADAM_ICRF_temp1 = Transform.EMEME2000_to_ICRF(eph_Adam_vectors['x_dot [m/s]'][i],eph_Adam_vectors['y_dot [m/s]'][i],eph_Adam_vectors['z_dot [m/s]'][i])       \n",
    "    # Pulls, X, Y, and Z velocity values   \n",
    "    eph_Adam_vectors['x_dot [m/s]'][i] = eph_ADAM_ICRF_temp1[0] \n",
    "    eph_Adam_vectors['y_dot [m/s]'][i] = eph_ADAM_ICRF_temp1[1] \n",
    "    eph_Adam_vectors['z_dot [m/s]'][i] = eph_ADAM_ICRF_temp1[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot ADAM and JPL \n",
    "  \n",
    "plot_size = max([np.abs(xObj).max() ]) \n",
    "size = [-plot_size-(plot_size*0.10), plot_size+(plot_size*0.10)]  \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1, projection ='3d')   \n",
    "\n",
    "# Plot JPL Object\n",
    "ax.plot(xObj,yObj,zObj, c = 'orange')\n",
    "\n",
    "#Plot ADAM Object\n",
    "ax.plot(xADAM_Obj,yADAM_Obj,zADAM_Obj,c='red')  \n",
    "\n",
    "#Plot ADAM Trans-to_ICRF Object\n",
    "ax.plot(TxvUdo,TyvUdo,TzvUdo,c='purple')   # In Development\n",
    "\n",
    "#Plot Earth\n",
    "ax.plot(xEarth,yEarth,zEarth,c='blue')\n",
    "\n",
    "\n",
    "ax.text(0.5*plot_size,0.5*plot_size,0.8*plot_size, asteroid + \" JPL\",color='orange')\n",
    "ax.text(0.5*plot_size,0.5*plot_size,0.5*plot_size, \"Earth\",color='blue')\n",
    "ax.text(0.5*plot_size,0.5*plot_size,0.2*plot_size, asteroid + \" ADAM\",color='red')\n",
    "ax.text(0.5*plot_size,0.5*plot_size,1.1*plot_size, asteroid + \" ADAM Transformed\",color='purple')\n",
    "#ax.text(0,1.5,2.3, asteroid + \" ADAM in ICRF\",color='purple')   # In development\n",
    "\n",
    "ax.set_xlim(size), ax.set_ylim(size), ax.set_zlim(size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cells allow you ro export the ADAM data to .csv and STK formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export ADAM or JPL data to CSV(Excel)\n",
    "\n",
    "OutputMethod = input(    'Enter 1 to export ADAM data, enter 2 to export JPL Data')\n",
    "OutputMethod = int(OutputMethod)\n",
    "print(\"This will default export location to your adam_home folder, you can modify this in the cell\") \n",
    "CSV_name = input(\"Enter file name\")\n",
    "CSV_export  = adam_home_defined + \"/\" +CSV_name+'.csv'\n",
    "\n",
    "if OutputMethod == 1 :\n",
    "    #pd.DataFrame(eph_ADAM_1).to_csv(CSV_export)\n",
    "    pd.DataFrame(eph_Adam_vectors).to_csv(CSV_export)  # Export Adam file  \n",
    "elif OutputMethod ==2 :\n",
    "    pd.DataFrame(eph_JPL_df).to_csv(CSV_export)     #Export JPL Data\n",
    "else: \n",
    "    print(\"Input not recognized\")\n",
    "# Note:  This currently pulls the ADAM data prior to coordinate transform.  \n",
    "# Once that function is developed further we'll need to call those data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Ephemeris to STK (In Development)\n",
    "\n",
    "Skip to last cell if you only want to export a .e file without opening STK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ephemeris:\")\n",
    "print(eph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from win32api import GetSystemMetrics\n",
    "from comtypes.client import CreateObject\n",
    "# Start STK on the desktop (on Microsoft Windows)\n",
    "uiApplication=CreateObject(\"STK11.Application\")\n",
    "uiApplication.Visible=True\n",
    "uiApplication.UserControl=True\n",
    "\n",
    "root = uiApplication.Personality2\n",
    "#stk_app = win.gencache.EnsureDispatch('STK11.Application')\n",
    "#stk_app.Visible = True\n",
    "#print(stk_app.__module__)\n",
    "\n",
    "#STK = stk_app.Personality\n",
    "#root = stk_app.Personality2\n",
    "from comtypes.gen import STKUtil\n",
    "from comtypes.gen import STKObjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root.NewScenario(\"ADAM_Starter\")\n",
    "scenario = root.CurrentScenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Scenario Time   If you changed default times above you'll need to manually format them here. \n",
    "scenario2 = scenario.QueryInterface(STKObjects.IAgScenario)\n",
    "scenario2.SetTimePeriod('04 Oct 2016 16:00:05.000', '04 Oct 2017 16:00:05.000')\n",
    "root.Rewind();\n",
    "#Default Start times\n",
    "#start_time_str='2016-10-04T00:00:00' #YYYY-Mon-Dy {HH:MM}   #Default: start_time_str='2016-10-04T00:00:00'\n",
    "#end_time_str='2017-10-11T00:00:00' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From AGI Help\n",
    "#3. Add a Satellite object to the scenario.\n",
    "satellite = scenario.Children.New(STKObjects.eSatellite, \"LeoSat\")\n",
    "#4. Propagate the Satellite object's orbit.\n",
    "root.ExecuteCommand('SetState */Satellite/LeoSat Classical TwoBody \"' + scenario2.StartTime + '\" \"'+ scenario2.StopTime +'\" 60 ICRF \"'+ scenario2.StartTime + '\" 7200000.0 0.0 90 0.0 0.0 0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use STK MTO (Multi Track Object) to store epehmeris points in STK\n",
    "#mto = root.CurrentScenario.Children('ADAM_Starter')\n",
    "#root.ExecuteCommand('VO */MTO/AsteroidTracks System \"CentralBody/Sun Inertial\"')\n",
    "#newMTO = mto.CopyObject('Temp') # satName)\n",
    "\n",
    "    # Add ephemeris file as MTO track\n",
    "    newTrack = mto.Tracks.Add(countNum)\n",
    "    newTrack.Points.LoadPoints(os.getcwd() + '/' + fileName)\n",
    "    \n",
    "    # Set graphics properties of track\n",
    "    newTrack.Interpolate = True\n",
    "    mto.Graphics.Tracks.GetTrackFromId(countNum).Line.Width = 1\n",
    "    mto.Graphics.Tracks.GetTrackFromId(countNum).Color = 0xe16941 # Blue Green Red: 225 105 065\n",
    "    mto.Graphics.Tracks.GetTrackFromId(countNum).Line.Translucency = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip to here to export .e file without opening STK. \n",
    "\n",
    "# Save ephemeris to STK \".e\" files, and add as track to MTO object in STK\n",
    "countNum = 1\n",
    "satName = asteroid\n",
    "satName = str(satName)\n",
    "    #Write ephemeris to file\n",
    "#eph = b.get_results().get_parts()[0].get_ephemeris()\n",
    "satName = '{:04d}'.format(countNum)\n",
    "fileName = '{}.e'.format(satName)\n",
    "print('STK satellite object name: {}    Ephemeris File Name: {}'.format(satName,fileName))\n",
    "with open(fileName, 'w') as f:\n",
    "        f.write(eph)\n",
    "    \n",
    "    # Add ephemeris file as MTO track\n",
    "#newTrack = mto.Tracks.Add(countNum)\n",
    "#newTrack.Points.LoadPoints(os.getcwd() + '/' + fileName)\n",
    "    \n",
    "    # Set graphics properties of track\n",
    "#newTrack.Interpolate = True\n",
    "#mto.Graphics.Tracks.GetTrackFromId(countNum).Line.Width = 1\n",
    "#mto.Graphics.Tracks.GetTrackFromId(countNum).Color = 0xe16941 # Blue Green Red: 225 105 065\n",
    "#mto.Graphics.Tracks.GetTrackFromId(countNum).Line.Translucency = 33\n",
    "    \n",
    "    # Increment count for unique ephemeris and STK satellite object name\n",
    "#countNum = countNum + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot RIC for JPL vs ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform ADAM coordinates\n",
    "for i in range (n):\n",
    "    # Transforms ADAM positions from EMEME2000 to ICRF\n",
    "    eph_ADAM_ICRF_temp1 = Transform.EMEME2000_to_ICRF(eph_JPLtoAdam_df['x [m]'][i],eph_JPLtoAdam_df['y [m]'][i],eph_JPLtoAdam_df['z [m]'][i])       \n",
    "    # Pulls, X, Y, and Z values   \n",
    "    eph_JPLtoAdam_df['x [m]'][i] = eph_ADAM_ICRF_temp1[0] \n",
    "    eph_JPLtoAdam_df['y [m]'][i] = eph_ADAM_ICRF_temp1[1] \n",
    "    eph_JPLtoAdam_df['z [m]'][i] = eph_ADAM_ICRF_temp1[1] \n",
    "\n",
    "# Transform velocities also\n",
    "    eph_ADAM_ICRF_temp1 = Transform.EMEME2000_to_ICRF(eph_JPLtoAdam_df['x_dot [m/s]'][i],eph_JPLtoAdam_df['y_dot [m/s]'][i],eph_JPLtoAdam_df['z_dot [m/s]'][i])       \n",
    "    # Pulls, X, Y, and Z values   \n",
    "    eph_JPLtoAdam_df['x [m]'][i] = eph_ADAM_ICRF_temp1[0] \n",
    "    eph_JPLtoAdam_df['y [m]'][i] = eph_ADAM_ICRF_temp1[1] \n",
    "    eph_JPLtoAdam_df['z [m]'][i] = eph_ADAM_ICRF_temp1[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JPL_R = np.array([np.array(eph_JPL_df.iloc[i,4:7])/np.linalg.norm(eph_JPL_df.iloc[i,4:7]) for i in range(0,len(eph_JPL_df))])\n",
    "JPLtoADAM_R = np.array([np.array(eph_JPLtoAdam_df.iloc[i,1:4])/np.linalg.norm(eph_JPLtoAdam_df.iloc[i,1:4]) for i in range(0,len(eph_JPLtoAdam_df))])\n",
    "JPL_ADAM_RIC_R = np.array([(JPLtoADAM_R[i]-JPL_R[i])/np.linalg.norm(JPLtoADAM_R[i]-JPL_R[i]) for i in range(0,len(JPL_R))])\n",
    "print(JPL_ADAM_RIC_R)\n",
    "JPL_V = np.array([np.array(eph_JPL_df.iloc[i,4:7])/np.sqrt(np.sum(np.square(eph_JPL_df.iloc[i,4:7]))) for i in range(0,len(eph_JPL_df))])\n",
    "JPLtoADAM_V = np.array([np.array(eph_JPLtoAdam_df.iloc[i,4:7])/np.sqrt(np.sum(np.square(eph_JPLtoAdam_df.iloc[i,4:7]))) for i in range(0,len(eph_JPLtoAdam_df))])\n",
    "JPL_ADAM_RIC_V = np.array([(JPLtoADAM_V[i]-JPL_V[i])/np.linalg.norm(JPLtoADAM_V[i]-JPL_V[i]) for i in range(0,len(JPL_R))])\n",
    "print(JPL_ADAM_RIC_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JPL_ADAM_RIC_C = np.array([np.cross(JPL_ADAM_RIC_R[i],JPL_ADAM_RIC_V[i]/np.linalg.norm(np.cross(JPL_ADAM_RIC_R[i],JPL_ADAM_RIC_V[i]))) for i in range(0,len(JPL_R))])\n",
    "JPL_ADAM_RIC_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JPL_ADAM_RIC_I = np.array([np.cross(JPL_ADAM_RIC_R[i],JPL_ADAM_RIC_C[i]/np.linalg.norm(np.cross(JPL_ADAM_RIC_R[i],JPL_ADAM_RIC_C[i]))) for i in range(0,len(JPL_R))])\n",
    "JPL_ADAM_RIC_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_times=atomic_times[0:len(atomic_times)-1]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.grid(True,ls='--')\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_R[:,0],linewidth=3,label=\"Radial\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_I[:,0],linewidth=3,label=\"Cross Track\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_C[:,0],linewidth=3,label=\"In Track\")\n",
    "plt.title(\"RIC for JPL vs ADAM (along x)\")\n",
    "plt.legend()\n",
    "plt.xlabel('Atomic Time')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_R[:,1],linewidth=3,label=\"Radial\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_I[:,1],linewidth=3,label=\"Cross Track\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_C[:,1],linewidth=3,label=\"In Track\")\n",
    "plt.grid(True)\n",
    "plt.title(\"RIC for JPL vs ADAM (along y)\")\n",
    "plt.xlabel('Atomic Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_R[:,2],linewidth=3,label=\"Radial\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_I[:,2],linewidth=3,label=\"Cross Track\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_C[:,2],linewidth=3,label=\"In Track\")\n",
    "plt.title(\"RIC for JPL vs ADAM (along z)\")\n",
    "plt.grid(True)\n",
    "plt.xlabel('Atomic Time')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(atomic_times[0:len(atomic_times)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently Asked Questions (FAQs)\n",
    "\n",
    "How to install Astroquery?  \n",
    "   To install Astroquery, pip install --pre astroquery     \n",
    "More details can be found at astroquery.jplhorizons https://astroquery.readthedocs.io/en/latest/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
